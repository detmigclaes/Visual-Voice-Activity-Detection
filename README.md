# Visual-Voice-Activity-Detection V-VAD
Project for Computer Vision F23

This project will explore methods for Voice Activity Detection.
This will include a review of methods in the following papers:

* Audio-video fusion strategies for active speaker
detection in meetings by Lionel Pibre, Francisco Madrigal, Cyrille Equoy, Fredéric Leraslé, Thomas Pellegrini, Julien Pinquier, Isabelle Ferrané

* RespVAD: Voice Activity Detection via Video-Extracted Respiration Patterns by Arnab Mondal and Prathosh A.P

* Vision-based Active Speaker Detection in Multiparty Interactions by Kalin Stefanov, Jonas Beskow, Giampiero Salvi

* S-VVAD: Visual Voice Activity Detection by Motion Segmentation by Muhammad Shahid, Cigdem Beyan, Vittorio Murino

* RealVAD: A Real-World Dataset and A Method for Voice Activity Detection by Body Motion Analysis by Cigdem Beyan, Muhammad Shahid, Vittorio Murino

We will also verify the code used by S-VVAD and RealVAD by running the models on the RealVAD dataset. 
This dataset has its origin in this YouTube video of a panel debate: www.youtube.com/watch?v=51pRTOIso4U 

We will also aim to verify the performance of the models on the Colombia dataset, whos nature is similar to that of RealVAD. 
This dataset can be found here: https://www.youtube.com/watch?v=6GzxbrO0DHM


By Oliver Fridorf and Claes Eske Harbo Jensen
